{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working in this notebook\n",
    "\n",
    "This jupyter notebook is set up to us a `bash` kernel. That means that the commands that we include\n",
    "in the code blocks will be executed by a bash shell, basically as if we typed them in the terminal.\n",
    "If you would rather work in a terminal, you can convert this document to a shell script through the `Export`\n",
    "file menu option. \n",
    "\n",
    "# Setup\n",
    "\n",
    "Installed in the docker image are python3, java, and conda. We will use those to bootstrap \n",
    "our environment as we go along. \n",
    "\n",
    "## [Install Nextflow](https://www.nextflow.io/docs/latest/getstarted.html#installation)\n",
    "\n",
    "Nextflow is distributed as a self-contained executable package, which means that it does not require any special installation procedure.\n",
    "\n",
    "It only needs two easy steps:\n",
    "\n",
    "- Download the executable package by copying and pasting the following command in your terminal window: `wget -qO- https://get.nextflow.io | bash`. It will create the nextflow main executable file in the current directory.\n",
    "\n",
    "- Optionally, move the nextflow file to a directory accessible by your `$PATH` variable (this is only required to avoid remembering and typing the full path to nextflow each time you need to run it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPSULE: Downloading dependency org.slf4j:log4j-over-slf4j:jar:1.7.25lease wait .. \n",
      "CAPSULE: Downloading dependency org.multiverse:multiverse-core:jar:0.7.0\n",
      "CAPSULE: Downloading dependency com.fasterxml.jackson.core:jackson-databind:jar:2.6.7.2\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-batch:jar:1.11.542\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-httpfs:jar:20.10.0\n",
      "CAPSULE: Downloading dependency joda-time:joda-time:jar:2.8.1\n",
      "CAPSULE: Downloading dependency com.beust:jcommander:jar:1.35\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-commons:jar:20.10.0\n",
      "CAPSULE: Downloading dependency org.jsoup:jsoup:jar:1.11.2\n",
      "CAPSULE: Downloading dependency ch.grengine:grengine:jar:1.3.0\n",
      "CAPSULE: Downloading dependency jline:jline:jar:2.9\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-nio:jar:3.0.5\n",
      "CAPSULE: Downloading dependency javax.mail:mail:jar:1.4.7\n",
      "CAPSULE: Downloading dependency org.slf4j:jul-to-slf4j:jar:1.7.25\n",
      "CAPSULE: Downloading dependency org.apache.httpcomponents:httpcore:jar:4.4.9\n",
      "CAPSULE: Downloading dependency com.fasterxml.jackson.core:jackson-core:jar:2.6.7\n",
      "CAPSULE: Downloading dependency ch.qos.logback:logback-classic:jar:1.1.11\n",
      "CAPSULE: Downloading dependency org.iq80.leveldb:leveldb-api:jar:0.12\n",
      "CAPSULE: Downloading dependency org.codehaus.gpars:gpars:jar:1.2.1\n",
      "CAPSULE: Downloading dependency com.esotericsoftware.kryo:kryo:jar:2.24.0\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-ec2:jar:1.11.542\n",
      "CAPSULE: Downloading dependency org.apache.ivy:ivy:jar:2.3.0\n",
      "CAPSULE: Downloading dependency com.googlecode.javaewah:JavaEWAH:jar:1.1.6\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-json:jar:3.0.5\n",
      "CAPSULE: Downloading dependency io.nextflow:nextflow:jar:20.10.0\n",
      "CAPSULE: Downloading dependency javax.activation:activation:jar:1.1.1\n",
      "CAPSULE: Downloading dependency com.jcraft:jsch:jar:0.1.54\n",
      "CAPSULE: Downloading dependency com.jcraft:jzlib:jar:1.1.1\n",
      "CAPSULE: Downloading dependency org.codehaus.jsr166-mirror:jsr166y:jar:1.7.0\n",
      "CAPSULE: Downloading dependency org.slf4j:slf4j-api:jar:1.7.25\n",
      "CAPSULE: Downloading dependency org.apache.httpcomponents:httpclient:jar:4.5.5\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-s3:jar:1.11.542\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy:jar:3.0.5\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-kms:jar:1.11.542\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-iam:jar:1.11.542\n",
      "CAPSULE: Downloading dependency ch.qos.logback:logback-core:jar:1.1.11\n",
      "CAPSULE: Downloading dependency com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.7\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-tower:jar:20.10.0\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-core:jar:1.11.542\n",
      "CAPSULE: Downloading dependency commons-lang:commons-lang:jar:2.6\n",
      "CAPSULE: Downloading dependency software.amazon.ion:ion-java:jar:1.0.2\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-templates:jar:3.0.5\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-xml:jar:3.0.5\n",
      "CAPSULE: Downloading dependency org.objenesis:objenesis:jar:2.1\n",
      "CAPSULE: Downloading dependency org.yaml:snakeyaml:jar:1.18\n",
      "CAPSULE: Downloading dependency org.slf4j:jcl-over-slf4j:jar:1.7.25\n",
      "CAPSULE: Downloading dependency io.nextflow:nxf-s3fs:jar:1.0.8\n",
      "CAPSULE: Downloading dependency com.google.guava:guava:jar:21.0\n",
      "CAPSULE: Downloading dependency com.amazonaws:jmespath-java:jar:1.11.542\n",
      "CAPSULE: Downloading dependency org.iq80.leveldb:leveldb:jar:0.12\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-amazon:jar:20.10.0\n",
      "CAPSULE: Downloading dependency com.amazonaws:aws-java-sdk-ecs:jar:1.11.542\n",
      "CAPSULE: Downloading dependency org.eclipse.jgit:org.eclipse.jgit:jar:5.2.1.201812262042-r\n",
      "CAPSULE: Downloading dependency com.fasterxml.jackson.core:jackson-annotations:jar:2.6.0\n",
      "CAPSULE: Downloading dependency commons-codec:commons-codec:jar:1.10\n",
      "                                                                        \n",
      "      N E X T F L O W\n",
      "      version 20.10.0 build 5430\n",
      "      created 01-11-2020 15:14 UTC \n",
      "      cite doi:10.1038/nbt.3820\n",
      "      http://nextflow.io\n",
      "\n",
      "\n",
      "Nextflow installation completed. Please note:\n",
      "- the executable file `nextflow` has been created in the folder: /home/jovyan/nextflow_on_jupyter\n",
      "- you may complete the installation by moving it to a directory in your $PATH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget -qO- https://get.nextflow.io | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to see that our nextflow works. Note here that I am addressing the `nextflow` executable without \n",
    "adding it to the path. I tend to work this way to keep the version of `nextflow` available tightly coupled to the project \n",
    "I'm working on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: nextflow [options] COMMAND [arg...]\n",
      "\n",
      "Options:\n",
      "  -C\n",
      "     Use the specified configuration file(s) overriding any defaults\n",
      "  -D\n",
      "     Set JVM properties\n",
      "  -bg\n",
      "     Execute nextflow in background\n",
      "  -c, -config\n",
      "     Add the specified file to configuration set\n",
      "  -d, -dockerize\n",
      "     Launch nextflow via Docker (experimental)\n",
      "  -h\n",
      "     Print this help\n",
      "  -log\n",
      "     Set nextflow log file path\n",
      "  -q, -quiet\n",
      "     Do not print information messages\n",
      "  -syslog\n",
      "     Send logs to syslog server (eg. localhost:514)\n",
      "  -v, -version\n",
      "     Print the program version\n",
      "\n",
      "Commands:\n",
      "  clean         Clean up project cache and work directories\n",
      "  clone         Clone a project into a folder\n",
      "  config        Print a project configuration\n",
      "  console       Launch Nextflow interactive console\n",
      "  drop          Delete the local copy of a project\n",
      "  help          Print the usage help for a command\n",
      "  info          Print project and system runtime information\n",
      "  kuberun       Execute a workflow in a Kubernetes cluster (experimental)\n",
      "  list          List all downloaded projects\n",
      "  log           Print executions log and runtime info\n",
      "  pull          Download or update a project\n",
      "  run           Execute a pipeline project\n",
      "  self-update   Update nextflow runtime to the latest available version\n",
      "  view          View project script file(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "./nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Bioconda channel (optional)\n",
    "\n",
    "As a first step, let's add the [Bioconda channel](https://bioconda.github.io/user/install.html#set-up-channels) (and conda-forge) to our conda installation.\n",
    "\n",
    "Since this is our first time interacting with code, note that the next block is a code block. \n",
    "Three commands are included in the block. Inside the code block, one can:\n",
    "\n",
    "1. Hit the play button.\n",
    "2. Hit shift-enter (which executes and moves to the next code block).\n",
    "3. Hit control-enter (which executes but does not move to the next code block).\n",
    "\n",
    "Make your choice now to add additional conda channels that we can use later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'defaults' already in 'channels' list, moving to the top\n",
      "Warning: 'bioconda' already in 'channels' list, moving to the top\n",
      "Warning: 'conda-forge' already in 'channels' list, moving to the top\n"
     ]
    }
   ],
   "source": [
    "conda config --add channels defaults\n",
    "conda config --add channels bioconda\n",
    "conda config --add channels conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double-check that this works by `getting` the conda channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--add channels 'defaults'   # lowest priority\n",
      "--add channels 'bioconda'\n",
      "--add channels 'conda-forge'   # highest priority\n"
     ]
    }
   ],
   "source": [
    "conda config --get channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we confirm that we added the channels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow\n",
    "\n",
    "## Functions\n",
    "\n",
    "Nextflow allows the definition of custom function in the workflow script using the following syntax:\n",
    "\n",
    "```\n",
    "def <function name> ( arg1, arg, .. ) {\n",
    "    <function body>\n",
    "}\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "def foo() {\n",
    "    'Hello world'\n",
    "}\n",
    "```\n",
    "\n",
    "```\n",
    "def bar(alpha, omega) {\n",
    "    alpha + omega\n",
    "}\n",
    "```\n",
    "\n",
    "The above snippet defines two simple functions, that can be invoked in the workflow script as foo() which returns the Hello world string and bar(10,20) which return the sum of two parameters.\n",
    "\n",
    "- Tip: Functions implicitly return the result of the last evaluated statement.\n",
    "\n",
    "The keyword `return` can be used to explicitly exit from a function returning the specified value. for example:\n",
    "\n",
    "```\n",
    "def fib( x ) {\n",
    "    if( x <= 1 )\n",
    "        return x\n",
    "    else\n",
    "        fib(x-1) + fib(x-2)\n",
    "}\n",
    "```\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's get our feet wet by running a file with a nextflow script in it. Since we have learned about functions, we can use this as our playground. The file of interest is available in `example_1` directory. Alternatively, [CLICK THIS LINK](01_example_functions/main2.nf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nextflow.preview.dsl=2\n",
      "\n",
      "\n",
      "/* foo takes no arguments \n",
      "   and returns a Hello World */\n",
      "\n",
      "def foo() {\n",
      "    'Hello world'\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "// bar takes two \"things\" \n",
      "// and returns their sum.\n",
      "\n",
      "def bar(alpha, omega) {\n",
      "    alpha + omega\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat 01_example_functions/main.nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 20.10.0\n",
      "Launching `example_1/main.nf` [festering_cantor] - revision: 75c8d1da04\n",
      "\u001b[33mWARN: DSL 2 IS AN EXPERIMENTAL FEATURE UNDER DEVELOPMENT -- SYNTAX MAY CHANGE IN FUTURE RELEASE\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "./nextflow run 01_example_functions/main.nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is interesting, but we didn't end up doing anything obvious. The functions `foo` and `bar` are never executed\n",
    "and we never print the result.\n",
    "\n",
    "Making a few additions, including `println` statements results in [this new file](01_example_functions/main2.nf).\n",
    "\n",
    "Running this file through nextflow produces results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./nextflow run 01_example_functions/main2.nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions, then, can be useful for encapsulating functionality, modularity, and for the star students, testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes\n",
    "\n",
    "Functions are useful for encapsulating code, but they are **not** the building blocks of a workflow or pipeline. In practice a Nextflow pipeline script is made by joining together different processes. Each process can be written in any scripting language that can be executed by the Linux platform (Bash, Perl, Ruby, Python, etc.).\n",
    "\n",
    "Processes are executed independently and are isolated from each other, i.e. they do not share a common (writable) state. The only way they can communicate is via asynchronous FIFO queues, called channels in Nextflow.\n",
    "\n",
    "Any process can define one or more channels as input and output. The interaction between these processes, and ultimately the pipeline execution flow itself, is implicitly defined by these input and output declarations.\n",
    "\n",
    "A Nextflow script looks like this:\n",
    "\n",
    "```\n",
    "nextflow.preview.dsl=2\n",
    "\n",
    "process foo {\n",
    "    output:\n",
    "      path 'foo.txt'\n",
    "    script:\n",
    "      \"\"\"\n",
    "      your_command > foo.txt\n",
    "      \"\"\"\n",
    "}\n",
    "\n",
    " process bar {\n",
    "    input:\n",
    "      path x\n",
    "    output:\n",
    "      path 'bar.txt'\n",
    "    script:\n",
    "      \"\"\"\n",
    "      another_command $x > bar.txt\n",
    "      \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    data = channel.fromPath('/some/path/*.txt')\n",
    "    foo()\n",
    "    bar(data)\n",
    "}\n",
    "```\n",
    "\n",
    "The above example defines two _processes_. Their *execution order* is not determined by the fact that the `foo` process comes before `bar` in the script (it could also be written the other way around).\n",
    "\n",
    "### Process composition\n",
    "Processes having matching input-output declaration can be composed so that the output of the first process is passed as input to the following process. Taking in consideration the previous process definition, it’s possible to write the following:\n",
    "\n",
    "```workflow {\n",
    "    bar(foo())\n",
    "}\n",
    "```\n",
    "\n",
    "### Process outputs\n",
    "A process output can also be accessed using the out attribute for the respective process object. For example:\n",
    "\n",
    "```\n",
    "workflow {\n",
    "    foo()\n",
    "    bar(foo.out)\n",
    "    bar.out.view()\n",
    "}\n",
    "```\n",
    "\n",
    "When a process defines two or more output channels, each of them can be accessed using the array element operator e.g. `out[0]`, `out[1]`, etc. or using named outputs (see below).\n",
    "\n",
    "#### Process named output\n",
    "\n",
    "The process output definition allows the use of the emit option to define a name identifier that can be used to reference the channel in the external scope. For example:\n",
    "\n",
    "```\n",
    "process foo {\n",
    "  output:\n",
    "    path '*.bam', emit: samples_bam\n",
    "\n",
    "  '''\n",
    "  your_command --here\n",
    "  '''\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    foo()\n",
    "    foo.out.samples_bam.view()\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "## Workflow\n",
    "\n",
    "The `workflow` block then defines how processes are related to each other through input parameters and outputs. In this case, because `foo` does not depend on `bar` outputs, these two processes **can** run in parallel (if resources to do so \n",
    "exist).\n",
    "\n",
    "### Workflow definition\n",
    "\n",
    "The workflow keyword allows the definition of sub-workflow components that enclose the invocation of one or more processes and operators:\n",
    "\n",
    "```\n",
    "workflow my_pipeline {\n",
    "    foo()\n",
    "    bar( foo.out.collect() )\n",
    "}\n",
    "```\n",
    "\n",
    "For example, the above snippet defines a workflow component, named my_pipeline, that can be invoked from another workflow component definition as any other function or process i.e. my_pipeline().\n",
    "\n",
    "### Workflow parameters\n",
    "\n",
    "A workflow component can access any variable and parameter defined in the outer scope:\n",
    "\n",
    "```\n",
    "params.data = '/some/data/file'\n",
    "\n",
    "workflow my_pipeline {\n",
    "    if( params.data )\n",
    "        bar(params.data)\n",
    "    else\n",
    "        bar(foo())\n",
    "}\n",
    "```\n",
    "\n",
    "### Workflow inputs\n",
    "\n",
    "A workflow component can declare one or more input channels using the take keyword. For example:\n",
    "\n",
    "```\n",
    "workflow my_pipeline {\n",
    "    take: data\n",
    "    main:\n",
    "    foo(data)\n",
    "    bar(foo.out)\n",
    "}\n",
    "```\n",
    "\n",
    "- Warning: When the take keyword is used, the beginning of the workflow body needs to be identified with the main keyword.\n",
    "\n",
    "Then, the input can be specified as an argument in the workflow invocation statement:\n",
    "\n",
    "```\n",
    "workflow {\n",
    "    my_pipeline( channel.from('/some/data') )\n",
    "}\n",
    "```\n",
    "\n",
    "Note\n",
    "\n",
    "Workflow inputs are by definition channel data structures. If a basic data type is provided instead, ie. number, string, list, etc. it’s implicitly converted to a channel value (ie. non-consumable).\n",
    "\n",
    "### Workflow outputs\n",
    "A workflow component can declare one or more out channels using the emit keyword. For example:\n",
    "\n",
    "```\n",
    "workflow my_pipeline {\n",
    "    main:\n",
    "      foo(data)\n",
    "      bar(foo.out)\n",
    "    emit:\n",
    "      bar.out\n",
    "}\n",
    "```\n",
    "\n",
    "Then, the result of the my_pipeline execution can be accessed using the out property ie. my_pipeline.out. When there are multiple output channels declared, use the array bracket notation to access each output component as described for the Process outputs definition.\n",
    "\n",
    "Alternatively, the output channel can be accessed using the identifier name which it’s assigned to in the emit declaration:\n",
    "\n",
    "```\n",
    "workflow my_pipeline {\n",
    "   main:\n",
    "     foo(data)\n",
    "     bar(foo.out)\n",
    "   emit:\n",
    "     my_data = bar.out\n",
    "}\n",
    "```\n",
    "\n",
    "Then, the result of the above snippet can accessed using my_pipeline.out.my_data.\n",
    "\n",
    "### Implicit workflow\n",
    "A workflow definition which does not declare any name is assumed to be the main workflow and it’s implicitly executed. Therefore it’s the entry point of the workflow application.\n",
    "\n",
    "- Note: Implicit workflow definition is ignored when a script is included as module. This allows the writing a workflow script that can be used either as a library module and as application script.\n",
    "\n",
    "- Tip: An alternative workflow entry can be specified using the -entry command line option.\n",
    "\n",
    "### Workflow composition\n",
    "\n",
    "Workflows defined in your script or imported by a module inclusion can be invoked and composed as any other process in your application.\n",
    "\n",
    "```\n",
    "workflow flow1 {\n",
    "    take: data\n",
    "    main:\n",
    "        foo(data)\n",
    "        bar(foo.out)\n",
    "    emit:\n",
    "        bar.out\n",
    "}\n",
    "\n",
    "workflow flow2 {\n",
    "    take: data\n",
    "    main:\n",
    "        foo(data)\n",
    "        baz(foo.out)\n",
    "    emit:\n",
    "        baz.out\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    take: data\n",
    "    main:\n",
    "      flow1(data)\n",
    "      flow2(flow1.out)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
